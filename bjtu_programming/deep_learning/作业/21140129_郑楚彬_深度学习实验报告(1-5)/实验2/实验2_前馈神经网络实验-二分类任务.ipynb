{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "automatic-superintendent",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def train_epoch(data_loader: Data.DataLoader, net: nn.Module,\n",
    "                loss_func, optimizer: torch.optim.Optimizer,\n",
    "                device='cpu'):\n",
    "    \"\"\"\n",
    "    训练迭代一次\n",
    "    :param data_loader: 生成器 (x, y)\n",
    "    :param net:         模型\n",
    "    :param loss_func:   损失函数\n",
    "    :param optimizer:   优化器\n",
    "    :param device:      设备\n",
    "    :return:    loss, acc\n",
    "    \"\"\"\n",
    "    net.train()\n",
    "    train_batch_num = len(data_loader)\n",
    "\n",
    "    # 一次迭代中的 Loss、正确样本数、总样本数\n",
    "    total_loss, correct, sample_num = 0, 0, 0\n",
    "\n",
    "    for batch_num, (x, y_true) in enumerate(data_loader):\n",
    "\n",
    "        # 将数据放入指定的设备\n",
    "        x = x.to(device).float()\n",
    "        y_true = y_true.to(device).long()\n",
    "\n",
    "        # 计算损失\n",
    "        y_hat: torch.Tensor = net(x)\n",
    "        loss = loss_func(y_hat, y_true)\n",
    "\n",
    "        # 取概率最大的类别索引\n",
    "        y_true: torch.Tensor = y_true.view(-1)\n",
    "        y_hat = y_hat.argmax(dim=1)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (y_true == y_hat).float().sum().item()\n",
    "        sample_num += len(y_true)\n",
    "\n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def test_epoch(data_loader: Data.DataLoader,\n",
    "               net: nn.Module, loss_func, device='cpu'):\n",
    "    \"\"\"\n",
    "    测试函数迭代一次\n",
    "    :param data_loader: 生成器 (x, y)\n",
    "    :param net:         模型\n",
    "    :param loss_func:   损失函数\n",
    "    :param device:      设备\n",
    "    :return:    loss, acc\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    train_batch_num = len(data_loader)\n",
    "\n",
    "    # 一次迭代中的 Loss、正确样本数、总样本数\n",
    "    total_loss, correct, sample_num = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_num, (x, y_true) in enumerate(data_loader):\n",
    "\n",
    "            # 将数据放入指定的设备\n",
    "            x = x.to(device).float()\n",
    "            y_true = y_true.to(device).long()\n",
    "\n",
    "            # 计算损失\n",
    "            y_hat: torch.Tensor = net(x)\n",
    "            loss = loss_func(y_hat, y_true)\n",
    "\n",
    "            # 取概率最大的类别索引\n",
    "            y_true: torch.Tensor = y_true.view(-1)\n",
    "            y_hat = y_hat.argmax(dim=1)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (y_true == y_hat).float().sum().item()\n",
    "            sample_num += len(y_true)\n",
    "\n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def plot_loss_accuracy(train_loss_list, train_acc_list,\n",
    "                       test_loss_list, test_acc_list, info=''):\n",
    "    \"\"\"\n",
    "    绘制 训练集和测试集正确率、损失值 的图形\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, len(train_loss_list), len(train_loss_list))\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(10, 6)\n",
    "    if info:\n",
    "        info = info + ' '\n",
    "\n",
    "    ax1.plot(x, train_loss_list, 'b-', label=\"train_loss\", lw=1)\n",
    "    ax1.plot(x, test_loss_list, 'r-', label=\"test_loss\", lw=1)\n",
    "    ax1.set_title(info + 'Loss')\n",
    "    ax1.legend(loc='best', frameon=False)\n",
    "    ax1.set_xlabel(\"epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(x, train_acc_list, 'b-', label=\"train_accuracy\", lw=1)\n",
    "    ax2.plot(x, test_acc_list, 'r-', label=\"test_accuracy\", lw=1)\n",
    "    ax2.set_title(info + 'Accuracy')\n",
    "    ax2.legend(loc='best', frameon=False)\n",
    "    ax2.set_xlabel(\"epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_by_dict(metrics: dict, shape: Tuple[int, int]):\n",
    "    \"\"\"\n",
    "    绘制图形 {指标: {参数值名1: [], 参数值名2: []}}\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(shape[0], shape[1])\n",
    "    axes = list(np.array(axes).ravel())\n",
    "    fig.set_size_inches(10*shape[0], 6*shape[1])\n",
    "\n",
    "    colors = ['b', 'r', 'y', 'c', 'k', 'g', 'w', 'm']\n",
    "    for ax_no, title in enumerate(metrics.keys()):\n",
    "        ax = axes[ax_no]\n",
    "        for i, (key, values) in enumerate(metrics.get(title, {}).items()):\n",
    "            x = np.linspace(0, len(values), len(values))\n",
    "            ax.plot(x, values, colors[i], label=key, lw=1)\n",
    "            ax.set_title(title)\n",
    "            ax.legend(loc='best', frameon=False)\n",
    "            ax.set_xlabel(\"epoch\")\n",
    "            ax.set_ylabel(title.lower().split(' ')[-1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-engineer",
   "metadata": {},
   "source": [
    "#### 手动生成二分类任务的数据集\n",
    "+ 共生成两个数据集。\n",
    "+ 两个数据集的大小均为10000且训练集大小为7000，测试集大小为3000。\n",
    "+ 两个数据集的样本特征`x的维度均为200`，且`分别服从均值互为相反数且方差相同的正态分布`。\n",
    "+ 两个数据集的样本`标签分别为0和1`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "veterinary-robertson",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14000, 200]) torch.Size([14000])\n",
      "torch.Size([6000, 200]) torch.Size([6000])\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(1)\n",
    "\n",
    "p = 200\n",
    "mu = 5\n",
    "std = 0.1\n",
    "train_size = 7000\n",
    "test_size = 3000\n",
    "\n",
    "x_train = torch.vstack([\n",
    "    torch.normal(mean=mu, std=std, size=(train_size, p)),\n",
    "    torch.normal(mean=-mu, std=std, size=(train_size, p))\n",
    "])\n",
    "y_train = torch.hstack([\n",
    "    torch.ones(train_size, dtype=torch.float),\n",
    "    torch.zeros(train_size, dtype=torch.float),\n",
    "])\n",
    "x_test = torch.vstack([\n",
    "    torch.normal(mean=mu, std=std, size=(test_size, p)),\n",
    "    torch.normal(mean=-mu, std=std, size=(test_size, p))\n",
    "])\n",
    "y_test = torch.hstack([\n",
    "    torch.ones(test_size, dtype=torch.float),\n",
    "    torch.zeros(test_size, dtype=torch.float),\n",
    "])\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# 构造数据集\n",
    "train_set = Data.TensorDataset(x_train, y_train)\n",
    "test_set = Data.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 手动实现前馈神经网络\n",
    "分析实验结果并绘制训练集和测试集的loss曲线"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appointed-sustainability",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss 0.017870, test_loss 0.000361, train_acc 0.990857, test_acc 1.000000\n",
      "epoch 2, train_loss 0.000241, test_loss 0.000165, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 3, train_loss 0.000131, test_loss 0.000105, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 4, train_loss 0.000089, test_loss 0.000076, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 5, train_loss 0.000067, test_loss 0.000059, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 6, train_loss 0.000053, test_loss 0.000048, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 7, train_loss 0.000044, test_loss 0.000040, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 8, train_loss 0.000038, test_loss 0.000035, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 9, train_loss 0.000033, test_loss 0.000031, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 10, train_loss 0.000029, test_loss 0.000027, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 11, train_loss 0.000026, test_loss 0.000024, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 12, train_loss 0.000023, test_loss 0.000022, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 13, train_loss 0.000021, test_loss 0.000020, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 14, train_loss 0.000019, test_loss 0.000019, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 15, train_loss 0.000018, test_loss 0.000017, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 16, train_loss 0.000017, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 17, train_loss 0.000016, test_loss 0.000015, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 18, train_loss 0.000015, test_loss 0.000014, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 19, train_loss 0.000014, test_loss 0.000013, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 20, train_loss 0.000013, test_loss 0.000013, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 21, train_loss 0.000012, test_loss 0.000012, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 22, train_loss 0.000012, test_loss 0.000011, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 23, train_loss 0.000011, test_loss 0.000011, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 24, train_loss 0.000011, test_loss 0.000010, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 25, train_loss 0.000010, test_loss 0.000010, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 26, train_loss 0.000010, test_loss 0.000009, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 27, train_loss 0.000009, test_loss 0.000009, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 28, train_loss 0.000009, test_loss 0.000009, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 29, train_loss 0.000009, test_loss 0.000008, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 30, train_loss 0.000008, test_loss 0.000008, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 31, train_loss 0.000008, test_loss 0.000008, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 32, train_loss 0.000008, test_loss 0.000007, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 33, train_loss 0.000007, test_loss 0.000007, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 34, train_loss 0.000007, test_loss 0.000007, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 35, train_loss 0.000007, test_loss 0.000007, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 36, train_loss 0.000007, test_loss 0.000007, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 37, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 38, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 39, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 40, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 41, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 42, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 43, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 44, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 45, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 46, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 47, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 48, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 49, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 50, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_iter(x: torch.Tensor, y: torch.Tensor, batch_size: int=8,\n",
    "              seed=1, shuffle=True):\n",
    "    \"\"\" 数据集生成器 \"\"\"\n",
    "\n",
    "    num_samples = x.shape[0]\n",
    "    indices = list(range(num_samples))\n",
    "    if shuffle:\n",
    "        random.seed(seed)\n",
    "        random.shuffle(indices)\n",
    "\n",
    "    # 构造小批次数据集\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "\n",
    "        # 选取的该批次内的行索引\n",
    "        j = torch.tensor(indices[i: min(i+batch_size, num_samples)])\n",
    "\n",
    "        yield x.index_select(dim=0, index=j), y.index_select(0, j)\n",
    "\n",
    "\n",
    "def sgd(lr, *params):\n",
    "    \"\"\"\n",
    "    优化器-梯度下降\n",
    "    :param lr:          学习率\n",
    "    :param params:      参数列表\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for param in params:\n",
    "        # 注意这里更改param时用的param.data\n",
    "        param.data -= lr * param.grad\n",
    "\n",
    "def sigmoid(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    激活函数-逻辑斯蒂回归\n",
    "    x: [batch_size, ]\n",
    "    :return [batch_size, 1]\n",
    "    \"\"\"\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "\n",
    "def binary_cross_entropy(y_hat: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    损失函数-二元交叉熵\n",
    "    :param y_hat(one_hot):   预测值 (batch_size, 1)\n",
    "    :param y_true:           真值  (batch_size)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_hat = y_hat.view(y_true.size())\n",
    "    l =  y_true * torch.log(y_hat) + (1-y_true) * torch.log(1 - y_hat)\n",
    "    return - l.sum()/y_true.shape[0]\n",
    "\n",
    "\n",
    "def relu(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    线性单元\n",
    "    :param x:\n",
    "    :param gamma:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x = torch.where(x >= 0, x, torch.zeros(x.size()))\n",
    "    return x\n",
    "\n",
    "def neural_net(x: torch.Tensor, *params) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    前馈神经网络\n",
    "    :param x:       特征\n",
    "    :param params:  模型参数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    w1, b1, w2, b2 = params\n",
    "    # hidden = tanh(torch.mm(x, w1) + b1)\n",
    "    # hidden = leak_relu(torch.mm(x, w1) + b1)\n",
    "    hidden = relu(torch.matmul(x, w1) + b1)\n",
    "    return sigmoid(torch.matmul(hidden, w2) + b2)\n",
    "\n",
    "\n",
    "def evaluate_loss_acc(data_iter, net, loss_fn, *params):\n",
    "    \"\"\"\n",
    "    返回测试集的loss\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    test_l_sum, acc_sum, num_batch, n = 0.0, 0.0, 0, 0\n",
    "    for x, y_true in data_iter:\n",
    "\n",
    "        y_hat = net(x, *params)\n",
    "        y_hat: torch.Tensor = y_hat.view(y_true.size())\n",
    "\n",
    "        test_l_sum += loss_fn(y_hat, y_true)\n",
    "\n",
    "        y_hat = torch.where(y_hat > 0.5, 1, 0)\n",
    "        acc_sum += (y_hat == y_true).float().sum().item()\n",
    "\n",
    "        num_batch += 1\n",
    "        n += y_true.shape[0]\n",
    "\n",
    "    return test_l_sum/num_batch, acc_sum/n\n",
    "\n",
    "\n",
    "# 参数配置\n",
    "num_inputs = x_train.shape[1]\n",
    "num_hiddens = 128\n",
    "num_outputs = 1\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "lr = 0.1\n",
    "net = neural_net\n",
    "loss = binary_cross_entropy\n",
    "\n",
    "# 模型训练 w = [w_0, ..., w_n]\n",
    "w1 = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_hiddens)),\n",
    "                  dtype=torch.float32)\n",
    "b1 = torch.zeros(num_hiddens, dtype=torch.float32)\n",
    "w2 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_outputs)),\n",
    "                  dtype=torch.float32)\n",
    "b2 = torch.zeros(num_outputs, dtype=torch.float32)\n",
    "\n",
    "params = (w1, b1, w2, b2)\n",
    "for param in params:\n",
    "    param.requires_grad_(requires_grad=True)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 读取数据集\n",
    "    iter_train = data_iter(x_train, y_train, batch_size=batch_size)\n",
    "    iter_test = data_iter(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    # 一批次的训练数据\n",
    "    train_l_sum, train_acc_sum, num_batch, n = 0.0, 0.0, 0, 0\n",
    "    for X, y_true in iter_train:\n",
    "\n",
    "        # 模型预测值\n",
    "        y_hat:torch.Tensor = net(X, *params)\n",
    "\n",
    "        # 损失值\n",
    "        l = loss(y_hat, y_true)\n",
    "\n",
    "        # 反向传播\n",
    "        l.backward()\n",
    "\n",
    "        # 随机梯度下降\n",
    "        sgd(lr, *params)\n",
    "\n",
    "        # 梯度置零\n",
    "        for param in params:\n",
    "            param.grad.data.zero_()\n",
    "\n",
    "        y_hat = y_hat.view(y_true.size())\n",
    "        y_hat = torch.where(y_hat > 0.5, 1, 0)\n",
    "        train_acc_sum += (y_hat == y_true).float().sum().item()\n",
    "        train_l_sum += l\n",
    "\n",
    "        num_batch += 1\n",
    "        n += y_true.shape[0]\n",
    "\n",
    "    train_l = train_l_sum / num_batch\n",
    "    train_acc = train_acc_sum / n\n",
    "    test_l, test_acc = evaluate_loss_acc(iter_test, net, loss, *params)\n",
    "\n",
    "    train_loss.append(train_l.detach().numpy())\n",
    "    test_loss.append(test_l.detach().numpy())\n",
    "    train_accuracy.append(train_acc)\n",
    "    test_accuracy.append(test_acc)\n",
    "    print('epoch %d, train_loss %f, test_loss %f, train_acc %f, test_acc %f'\n",
    "          % (epoch+1, train_l, test_l, train_acc_sum/n, test_acc))\n",
    "\n",
    "\n",
    "plot_loss_accuracy(train_loss, train_accuracy, test_loss, test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### torch.nn实现前馈神经网络\n",
    "分析实验结果并绘制训练集和测试集的loss曲线"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class TorchNeuron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 activation=nn.ReLU, num_layers=1, drop_out_rate=0):\n",
    "        super(TorchNeuron, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = activation\n",
    "        self.drop_out_rate = drop_out_rate\n",
    "\n",
    "        self.linear = nn.Sequential(*self.create_linear_layers())\n",
    "\n",
    "        for param in self.linear.parameters():\n",
    "            nn.init.normal_(param, std=0.01)\n",
    "\n",
    "    def create_linear_layers(self) -> Tuple[nn.Module]:\n",
    "        \"\"\"\n",
    "        创建层\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        modules = [\n",
    "            nn.Linear(self.input_size, self.hidden_size),\n",
    "            self.activation(),\n",
    "            nn.Dropout(self.drop_out_rate),\n",
    "        ]\n",
    "        for i in range(self.num_layers - 1):\n",
    "            modules.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            modules.append(self.activation())\n",
    "            modules.append(nn.Dropout(self.drop_out_rate))\n",
    "        modules.append(nn.Linear(self.hidden_size, self.output_size))\n",
    "        return tuple(modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss 0.013385, test_loss 0.000146, train_acc 0.990643, test_acc 1.000000\n",
      "epoch 2, train_loss 0.000104, test_loss 0.000075, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 3, train_loss 0.000061, test_loss 0.000050, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 4, train_loss 0.000043, test_loss 0.000037, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 5, train_loss 0.000033, test_loss 0.000030, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 6, train_loss 0.000027, test_loss 0.000025, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 7, train_loss 0.000023, test_loss 0.000021, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 8, train_loss 0.000020, test_loss 0.000018, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 9, train_loss 0.000017, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 10, train_loss 0.000015, test_loss 0.000014, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 11, train_loss 0.000014, test_loss 0.000013, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 12, train_loss 0.000012, test_loss 0.000012, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 13, train_loss 0.000011, test_loss 0.000011, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 14, train_loss 0.000011, test_loss 0.000010, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 15, train_loss 0.000010, test_loss 0.000009, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 16, train_loss 0.000009, test_loss 0.000009, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 17, train_loss 0.000009, test_loss 0.000008, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 18, train_loss 0.000008, test_loss 0.000008, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 19, train_loss 0.000008, test_loss 0.000007, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 20, train_loss 0.000007, test_loss 0.000007, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 21, train_loss 0.000007, test_loss 0.000007, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 22, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 23, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 24, train_loss 0.000006, test_loss 0.000006, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 25, train_loss 0.000006, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 26, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 27, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 28, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 29, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 30, train_loss 0.000005, test_loss 0.000005, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 31, train_loss 0.000004, test_loss 0.000004, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 32, train_loss 0.000004, test_loss 0.000004, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 33, train_loss 0.000004, test_loss 0.000004, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 34, train_loss 0.000004, test_loss 0.000004, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 35, train_loss 0.000004, test_loss 0.000004, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 36, train_loss 0.000004, test_loss 0.000004, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 37, train_loss 0.000004, test_loss 0.000004, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 38, train_loss 0.000004, test_loss 0.000004, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 39, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 40, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 41, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 42, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 43, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 44, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 45, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 46, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 47, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 48, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 49, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n",
      "epoch 50, train_loss 0.000003, test_loss 0.000003, train_acc 1.000000, test_acc 1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 参数配置\n",
    "device = 'cpu'\n",
    "input_size = x_train.shape[1]\n",
    "hidden_size = 256\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "lr = 0.1\n",
    "\n",
    "net = TorchNeuron(input_size, hidden_size, output_size)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 构造数据集\n",
    "dataset_train = Data.TensorDataset(x_train, y_train)\n",
    "dataset_test = Data.TensorDataset(x_test, y_test)\n",
    "\n",
    "# 读取数据集\n",
    "iter_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "iter_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    train_loss, train_acc = train_epoch(data_loader=train_data_loader, net=net,\n",
    "                                        loss_func=loss_func, optimizer=optimizer, device=device)\n",
    "    test_loss, test_acc = test_epoch(data_loader=test_data_loader, net=net,\n",
    "                                     loss_func=loss_func, device=device)\n",
    "\n",
    "    print('epoch %d, train_loss %f, test_loss %f, train_acc %f, test_acc %f'\n",
    "          % (epoch+1, train_loss, test_loss, train_acc, test_acc))\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "\n",
    "plot_loss_accuracy(train_loss_list, train_acc_list, test_loss_list, test_acc_list)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 采用10折交叉验证评估实验结果\n",
    "要求除了最终结果外还需以表格的形式展示每折的实验结果"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.009769, test_loss 0.000130, train_acc 0.994444, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000102, test_loss 0.000062, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000066, test_loss 0.000041, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000052, test_loss 0.000031, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000042, test_loss 0.000025, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000036, test_loss 0.000022, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000033, test_loss 0.000020, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000031, test_loss 0.000018, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000029, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000027, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.010057, test_loss 0.000093, train_acc 0.993500, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000104, test_loss 0.000047, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000065, test_loss 0.000032, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000050, test_loss 0.000025, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000042, test_loss 0.000021, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000036, test_loss 0.000018, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000032, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000029, test_loss 0.000015, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000027, test_loss 0.000014, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000026, test_loss 0.000013, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.010436, test_loss 0.000094, train_acc 0.992000, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000107, test_loss 0.000048, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000067, test_loss 0.000033, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000051, test_loss 0.000026, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000042, test_loss 0.000021, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000036, test_loss 0.000019, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000032, test_loss 0.000017, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000029, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000027, test_loss 0.000015, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000026, test_loss 0.000014, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.009859, test_loss 0.000094, train_acc 0.995556, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000108, test_loss 0.000048, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000069, test_loss 0.000033, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000050, test_loss 0.000026, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000042, test_loss 0.000021, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000036, test_loss 0.000019, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000032, test_loss 0.000017, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000030, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000028, test_loss 0.000015, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000027, test_loss 0.000014, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.009548, test_loss 0.000126, train_acc 0.996944, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000093, test_loss 0.000062, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000062, test_loss 0.000042, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000049, test_loss 0.000032, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000041, test_loss 0.000027, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000035, test_loss 0.000023, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000033, test_loss 0.000021, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000029, test_loss 0.000019, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000027, test_loss 0.000018, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000027, test_loss 0.000017, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.009969, test_loss 0.000116, train_acc 0.994611, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000094, test_loss 0.000058, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000062, test_loss 0.000040, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000046, test_loss 0.000031, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000039, test_loss 0.000026, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000034, test_loss 0.000023, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000030, test_loss 0.000020, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000029, test_loss 0.000019, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000027, test_loss 0.000018, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000025, test_loss 0.000017, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.009845, test_loss 0.000122, train_acc 0.995667, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000116, test_loss 0.000062, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000072, test_loss 0.000043, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000055, test_loss 0.000033, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000044, test_loss 0.000028, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000040, test_loss 0.000024, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000034, test_loss 0.000022, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000031, test_loss 0.000020, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000029, test_loss 0.000019, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000028, test_loss 0.000018, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.010350, test_loss 0.000111, train_acc 0.993278, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000111, test_loss 0.000055, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000070, test_loss 0.000037, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000053, test_loss 0.000028, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000041, test_loss 0.000024, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000037, test_loss 0.000021, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000033, test_loss 0.000019, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000031, test_loss 0.000017, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000028, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000027, test_loss 0.000015, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.009715, test_loss 0.000077, train_acc 0.997278, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000104, test_loss 0.000040, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000067, test_loss 0.000028, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000052, test_loss 0.000022, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000043, test_loss 0.000019, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000038, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000033, test_loss 0.000015, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000031, test_loss 0.000014, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000029, test_loss 0.000013, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000027, test_loss 0.000012, train_acc 1.000000, test_acc 1.000000\n",
      "TorchNeuron(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "lr=0.1 epoch 1, train_loss 0.009902, test_loss 0.000104, train_acc 0.995278, test_acc 1.000000\n",
      "lr=0.1 epoch 2, train_loss 0.000112, test_loss 0.000052, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 3, train_loss 0.000070, test_loss 0.000035, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 4, train_loss 0.000052, test_loss 0.000027, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 5, train_loss 0.000044, test_loss 0.000023, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 6, train_loss 0.000038, test_loss 0.000020, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 7, train_loss 0.000034, test_loss 0.000018, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 8, train_loss 0.000031, test_loss 0.000016, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 9, train_loss 0.000029, test_loss 0.000015, train_acc 1.000000, test_acc 1.000000\n",
      "lr=0.1 epoch 10, train_loss 0.000027, test_loss 0.000014, train_acc 1.000000, test_acc 1.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def train(train_data_loader, test_data_loader):\n",
    "\n",
    "    net = TorchNeuron(input_size, hidden_size, output_size, drop_out_rate=0.3)\n",
    "    print(net)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, weight_decay=0.0)\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_loss_list = []\n",
    "    test_acc_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        train_loss, train_acc = train_epoch(data_loader=train_data_loader, net=net,\n",
    "                                            loss_func=loss_func, optimizer=optimizer, device=device)\n",
    "        test_loss, test_acc = test_epoch(data_loader=test_data_loader, net=net,\n",
    "                                         loss_func=loss_func, device=device)\n",
    "\n",
    "        print('lr=%s epoch %d, train_loss %f, test_loss %f, train_acc %f, test_acc %f'\n",
    "              % (lr, epoch+1, train_loss, test_loss, train_acc, test_acc))\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_loss_list.append(test_loss)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "    return train_loss_list, train_acc_list, test_loss_list, test_acc_list\n",
    "\n",
    "# 参数配置\n",
    "device = 'cpu'\n",
    "input_size = x_train.shape[1]\n",
    "hidden_size = 256\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "lr = 0.1\n",
    "\n",
    "X = torch.cat((x_train, x_test))\n",
    "y = torch.cat((y_train, y_test))\n",
    "\n",
    "indices = np.arange(0, X.shape[0])\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "kf_train_loss, kf_train_acc, kf_test_loss, kf_test_acc = [], [], [], []\n",
    "for train_index, test_index in kf.split(indices):\n",
    "    train_index = torch.LongTensor(train_index)\n",
    "    test_index = torch.LongTensor(test_index)\n",
    "\n",
    "    train_x = torch.index_select(X, dim=0, index=train_index)\n",
    "    train_y = torch.index_select(y, dim=0, index=train_index)\n",
    "    test_x = torch.index_select(X, dim=0, index=test_index)\n",
    "    test_y = torch.index_select(y, dim=0, index=test_index)\n",
    "\n",
    "    train_set = Data.TensorDataset(train_x, train_y)\n",
    "    test_set = Data.TensorDataset(test_x, test_y)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 训练\n",
    "    train_loss_list, train_acc_list, test_loss_list, test_acc_list = train(train_data_loader, test_data_loader)\n",
    "\n",
    "    kf_train_loss.append(train_loss_list)\n",
    "    kf_train_acc.append(train_acc_list)\n",
    "    kf_test_loss.append(test_loss_list)\n",
    "    kf_test_acc.append(test_acc_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.55238345e-05 1.34269281e-05 1.41567948e-05 1.38647451e-05\n",
      " 1.70274982e-05 1.67884380e-05 1.78620262e-05 1.52344270e-05\n",
      " 1.20956392e-05 1.44826975e-05]\n",
      "[3.80892912e-05 2.95931347e-05 3.02551834e-05 3.00995494e-05\n",
      " 3.87915284e-05 3.66381004e-05 3.89902085e-05 3.42971369e-05\n",
      " 2.55111829e-05 3.24274791e-05]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "kf_train_loss_np = np.array(kf_train_loss)\n",
    "kf_train_acc_np = np.array(kf_train_acc)\n",
    "\n",
    "kf_test_loss_np = np.array(kf_test_loss)\n",
    "kf_test_acc_np = np.array(kf_test_acc)\n",
    "\n",
    "print(kf_test_loss_np.min(axis=1))\n",
    "print(kf_test_loss_np.mean(axis=1))\n",
    "\n",
    "print(kf_test_acc_np.max(axis=1))\n",
    "print(kf_test_acc_np.mean(axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}